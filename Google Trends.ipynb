{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76dce287-7c64-499d-9e6a-3d6923eaefeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/38] fetching: 'Cards Against Humanity'\n",
      "   -> saved trends_out/cards_against_humanity.csv (263 rows)\n",
      "[2/38] fetching: 'Baby Einstein Toy'\n",
      "   -> saved trends_out/baby_einstein_toy.csv (263 rows)\n",
      "[3/38] fetching: 'Exploding Kittens'\n",
      "   -> saved trends_out/exploding_kittens.csv (263 rows)\n",
      "[4/38] fetching: 'baby stacking cups'\n",
      "   -> saved trends_out/baby_stacking_cups.csv (263 rows)\n",
      "[5/38] fetching: 'dyson vacuum toy'\n",
      "   -> saved trends_out/dyson_vacuum_toy.csv (263 rows)\n",
      "[6/38] fetching: 'what do you meme'\n",
      "   -> saved trends_out/what_do_you_meme.csv (263 rows)\n",
      "[7/38] fetching: 'stuffed elephant'\n",
      "   -> saved trends_out/stuffed_elephant.csv (263 rows)\n",
      "[8/38] fetching: 'jenga'\n",
      "   -> saved trends_out/jenga.csv (263 rows)\n",
      "[9/38] fetching: 'automatic card shuffler'\n",
      "   -> saved trends_out/automatic_card_shuffler.csv (263 rows)\n",
      "[10/38] fetching: 'princess castle tent'\n",
      "   -> saved trends_out/princess_castle_tent.csv (263 rows)\n",
      "[11/38] fetching: 'magnet tiles'\n",
      "   -> saved trends_out/magnet_tiles.csv (263 rows)\n",
      "[12/38] fetching: 'pokemon cards'\n",
      "   -> saved trends_out/pokemon_cards.csv (263 rows)\n",
      "[13/38] fetching: 'five crowns'\n",
      "   -> saved trends_out/five_crowns.csv (263 rows)\n",
      "[14/38] fetching: 'gumby toy'\n",
      "   -> saved trends_out/gumby_toy.csv (263 rows)\n",
      "[15/38] fetching: 'ticket to ride'\n",
      "   -> saved trends_out/ticket_to_ride.csv (263 rows)\n",
      "[16/38] fetching: 'sequence game'\n",
      "   -> saved trends_out/sequence_game.csv (263 rows)\n",
      "[17/38] fetching: 'left right center'\n",
      "   -> saved trends_out/left_right_center.csv (263 rows)\n",
      "[18/38] fetching: 'connect 4'\n",
      "   -> saved trends_out/connect_4.csv (263 rows)\n",
      "[19/38] fetching: 'drone toy'\n",
      "   -> saved trends_out/drone_toy.csv (263 rows)\n",
      "[20/38] fetching: 'monopoly deal'\n",
      "   -> saved trends_out/monopoly_deal.csv (263 rows)\n",
      "[21/38] fetching: 'little tikes basketball'\n",
      "   -> saved trends_out/little_tikes_basketball.csv (263 rows)\n",
      "[22/38] fetching: 'suspend game'\n",
      "   -> saved trends_out/suspend_game.csv (263 rows)\n",
      "[23/38] fetching: 'Ultimate kitchen playset'\n",
      "   -> saved trends_out/ultimate_kitchen_playset.csv (263 rows)\n",
      "[24/38] fetching: 'Play kitchen'\n",
      "   -> saved trends_out/play_kitchen.csv (263 rows)\n",
      "[25/38] fetching: 'Kid roller coaster'\n",
      "   -> saved trends_out/kid_roller_coaster.csv (263 rows)\n",
      "[26/38] fetching: 'HD drone'\n",
      "   -> saved trends_out/hd_drone.csv (263 rows)\n",
      "[27/38] fetching: '4k drone'\n",
      "   -> saved trends_out/4k_drone.csv (263 rows)\n",
      "[28/38] fetching: 'Polar express toy train'\n",
      "   -> saved trends_out/polar_express_toy_train.csv (263 rows)\n",
      "[29/38] fetching: 'BB-8 Toy'\n",
      "   -> saved trends_out/bb_8_toy.csv (263 rows)\n",
      "[30/38] fetching: 'Mini John Deere'\n",
      "   -> saved trends_out/mini_john_deere.csv (263 rows)\n",
      "[31/38] fetching: 'Magna Tiles'\n",
      "   -> saved trends_out/magna_tiles.csv (263 rows)\n",
      "[32/38] fetching: 'Remote control monster truck'\n",
      "   -> saved trends_out/remote_control_monster_truck.csv (263 rows)\n",
      "[33/38] fetching: 'GPS drone'\n",
      "   -> saved trends_out/gps_drone.csv (263 rows)\n",
      "[34/38] fetching: 'Camera drone'\n",
      "   -> saved trends_out/camera_drone.csv (263 rows)\n",
      "[35/38] fetching: 'Vector robot'\n",
      "   -> saved trends_out/vector_robot.csv (263 rows)\n",
      "[36/38] fetching: 'Mini bounce house'\n",
      "   -> saved trends_out/mini_bounce_house.csv (263 rows)\n",
      "[37/38] fetching: 'Jumbo doll house'\n",
      "   -> saved trends_out/jumbo_doll_house.csv (263 rows)\n",
      "[38/38] fetching: 'Mini play kitchen'\n",
      "   -> saved trends_out/mini_play_kitchen.csv (263 rows)\n",
      "\n",
      "ALL DONE. Big file saved: trends_out/all_terms_long.csv  (rows: 9,994)\n"
     ]
    }
   ],
   "source": [
    "# google_trends_scrape_save.py\n",
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, time, re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ==== Grug settings ====\n",
    "TERMS = [\n",
    "    \"Cards Against Humanity\",\n",
    "    \"Baby Einstein Toy\",\n",
    "    \"Exploding Kittens\",\n",
    "    \"baby stacking cups\",\n",
    "    \"dyson vacuum toy\",\n",
    "    \"what do you meme\",\n",
    "    \"stuffed elephant\",\n",
    "    \"jenga\",\n",
    "    \"automatic card shuffler\",\n",
    "    \"princess castle tent\",\n",
    "    \"magnet tiles\",\n",
    "    \"pokemon cards\",\n",
    "    \"five crowns\",\n",
    "    \"gumby toy\",\n",
    "    \"ticket to ride\",\n",
    "    \"sequence game\",\n",
    "    \"left right center\",\n",
    "    \"connect 4\",\n",
    "    \"drone toy\",\n",
    "    \"monopoly deal\",\n",
    "    \"little tikes basketball\",\n",
    "    \"suspend game\",\n",
    "    \"Ultimate kitchen playset\",\n",
    "    \"Play kitchen\",\n",
    "    \"Kid roller coaster\",\n",
    "    \"HD drone\",\n",
    "    \"4k drone\",\n",
    "    \"Polar express toy train\",\n",
    "    \"BB-8 Toy\",\n",
    "    \"Mini John Deere\",\n",
    "    \"Magna Tiles\",\n",
    "    \"Remote control monster truck\",\n",
    "    \"GPS drone\",\n",
    "    \"Camera drone\",\n",
    "    \"Vector robot\",\n",
    "    \"Mini bounce house\",\n",
    "    \"Jumbo doll house\",\n",
    "    \"Mini play kitchen\"\n",
    "]\n",
    "\n",
    "TIMEFRAME = \"2004-01-01 2025-11-01\"   # small range (e.g., last 90 days) gives daily; long range gives weekly\n",
    "OUT_DIR = \"trends_out\"                # folder will be made if not exist\n",
    "SLEEP_SEC = 1.5                       # be nice to magic rock; can bump to 3â€“5 if rate-limited\n",
    "RETRIES = 3\n",
    "\n",
    "# ==== small helpers ====\n",
    "def safe_name(s: str) -> str:\n",
    "    s = s.strip().lower().replace(\"&\", \"and\").replace(\"+\", \"plus\")\n",
    "    s = re.sub(r\"[^a-z0-9]+\", \"_\", s)\n",
    "    return s.strip(\"_\")\n",
    "\n",
    "def infer_windows(index: pd.DatetimeIndex):\n",
    "    \"\"\"Guess if series is daily or weekly. Set window sizes accordingly.\"\"\"\n",
    "    if len(index) < 3:\n",
    "        # default to weekly if tiny\n",
    "        return {\"month\": 4, \"sixmo\": 24, \"year\": 52}\n",
    "    diffs = pd.Series(index[1:]).reset_index(drop=True) - pd.Series(index[:-1]).reset_index(drop=True)\n",
    "    step_days = diffs.median().days if len(diffs) else 7\n",
    "    # daily if ~1 day cadence\n",
    "    if step_days <= 2:\n",
    "        return {\"month\": 30, \"sixmo\": 182, \"year\": 365}  # ~calendar days\n",
    "    else:\n",
    "        return {\"month\": 4, \"sixmo\": 24, \"year\": 52}     # ~weeks\n",
    "\n",
    "def add_ratios(df: pd.DataFrame, value_col: str) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    wins = infer_windows(df.index)\n",
    "    # Rolling with min_periods=window so ratios start when stable\n",
    "    m_mean  = df[value_col].rolling(wins[\"month\"],  min_periods=wins[\"month\"]).mean()\n",
    "    s6_mean = df[value_col].rolling(wins[\"sixmo\"],  min_periods=wins[\"sixmo\"]).mean()\n",
    "    y_mean  = df[value_col].rolling(wins[\"year\"],   min_periods=wins[\"year\"]).mean()\n",
    "    df[\"ratio_month\"] = df[value_col] / m_mean\n",
    "    df[\"ratio_6mo\"]   = df[value_col] / s6_mean\n",
    "    df[\"ratio_year\"]  = df[value_col] / y_mean\n",
    "    return df\n",
    "\n",
    "def fetch_one(pytrends: TrendReq, term: str, timeframe: str) -> pd.DataFrame:\n",
    "    # retry loop (in case of 429 or hiccup)\n",
    "    last_err = None\n",
    "    for attempt in range(1, RETRIES + 1):\n",
    "        try:\n",
    "            pytrends.build_payload([term], timeframe=timeframe)\n",
    "            df = pytrends.interest_over_time()\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            wait = SLEEP_SEC * attempt\n",
    "            time.sleep(wait)\n",
    "    raise last_err\n",
    "\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "pytrends = TrendReq(hl=\"en-US\", tz=360)\n",
    "\n",
    "all_rows = []  # for big long table\n",
    "\n",
    "for i, term in enumerate(TERMS, 1):\n",
    "    print(f\"[{i}/{len(TERMS)}] fetching: {term!r}\")\n",
    "    time.sleep(SLEEP_SEC)  # gentle pacing\n",
    "\n",
    "    raw = fetch_one(pytrends, term, TIMEFRAME)\n",
    "\n",
    "    if raw.empty:\n",
    "        print(f\"   -> empty for {term}; skip\")\n",
    "        continue\n",
    "\n",
    "    # Normalize & clean\n",
    "    term_col = term  # pytrends uses the exact term as column name\n",
    "    if \"isPartial\" in raw.columns:\n",
    "        raw = raw[~raw[\"isPartial\"].astype(bool)].drop(columns=[\"isPartial\"])  # drop partial last row\n",
    "    raw.index = pd.to_datetime(raw.index)\n",
    "\n",
    "    # Add ratios\n",
    "    out = add_ratios(raw, term_col)\n",
    "    out = out.rename(columns={term_col: \"value\"})\n",
    "    out[\"term\"] = term\n",
    "\n",
    "    # Save per-term CSV\n",
    "    fn = os.path.join(OUT_DIR, f\"{safe_name(term)}.csv\")\n",
    "    out.to_csv(fn, index_label=\"date\")\n",
    "    print(f\"   -> saved {fn} ({len(out):,} rows)\")\n",
    "\n",
    "    # Add to big long table\n",
    "    all_rows.append(out.reset_index())\n",
    "\n",
    "# Save big CSV (all terms stacked)\n",
    "if all_rows:\n",
    "    big = pd.concat(all_rows, ignore_index=True)\n",
    "    big = big[[\"date\", \"term\", \"value\", \"ratio_month\", \"ratio_6mo\", \"ratio_year\"]]\n",
    "    big.sort_values([\"term\", \"date\"], inplace=True)\n",
    "    big_fn = os.path.join(OUT_DIR, \"all_terms_long.csv\")\n",
    "    big.to_csv(big_fn, index=False)\n",
    "    print(f\"\\nALL DONE. Big file saved: {big_fn}  (rows: {len(big):,})\")\n",
    "else:\n",
    "    print(\"No data fetched. Check TERMS or timeframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2879a2-8b60-424f-bf8c-1e9a198aca15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
